{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scipy-Stats Juptyer Notebook\n",
    "*****\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Outline of this Notebook:\n",
    "\n",
    "1. Overview of Scipy Stats Jupyter Notebook\n",
    "2. Analysis of Variance(Anova)\n",
    "3. Dataset: Diet\n",
    "    - Importing Packages for the Notebook\n",
    "    - Exploring the Dataset\n",
    "    - Preprocessing the Data\n",
    "4. Hypothesis and Assumption Testing of Dataset to meet Anova Requirements\n",
    "5. Conducting the Anova Test\n",
    "6. Conclusion\n",
    "7. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Scipy Stats Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Scipy-stats module is a sub-package of the SciPy library providing many uses for statistical analysis including probabilistic distributions, random variables and statistical operations. https://data-flair.training/blogs/scipy-statistical-functions/ It is used to analyse normal distributions and calculate different distribution values with a number of in built methods available.https://www.delftstack.com/api/scipy/scipy-scipy.stats.norm-method/. \n",
    "<br>\n",
    "Within the library, there are functions for both continious and discrete functions that have the ability to work with different types of distributions and performs hypothesis and t-tests.https://data-flair.training/blogs/scipy-statistical-functions/?ref=morioh.com&utm_source=morioh.com. The library works seamlessly with other packages to enable statistics calculations, descriptive analysis and data visualisation. These include:\n",
    "- pandas\n",
    "<br>\n",
    "- matplotlib\n",
    "<br>\n",
    "- seaborn\n",
    "<br>\n",
    "- numpy\n",
    "<br>\n",
    "\n",
    "\n",
    "**Some of the Key Terms in Statistical Analysis that will be referred to in this library** https://realpython.com/python-statistics/\n",
    "<br>\n",
    "<br>\n",
    "**Types of Variables**\n",
    "<br>\n",
    "- **Dependent Variable** The chosen data category that is examined to see if there is any affect from the independent variables\n",
    "- **Indepedent Variable:** These are the chosen datapoints measured that may have an effect on the dependent variable\n",
    "<br>\n",
    "**Measures of of Central Tendency**\n",
    "<br>\n",
    "- **Mean**: the average of all the items in the dataset.\n",
    "- **Median**: the middle element of a sorted dataset.\n",
    "<br>\n",
    "**Measures of Variability**\n",
    "<br>\n",
    " - **Variance**: the average of the squared differences from the mean \n",
    "$$Var(X) = E(X^2) - (E(X))^2$$\n",
    "<br>\n",
    "- **Standard Deviation**: is a measure of how spread out numbers are and is calculated by determining the square root of the variance https://www.mathsisfun.com/data/standard-deviation.html\n",
    "<br>\n",
    "$$e^x=\\sum_{i=0}^\\infty \\frac{1}{i!}x^i$$\n",
    "<br>\n",
    "- **Percentiles** \n",
    "<br>\n",
    "*is the element in the dataset such that p% of the elements in the dataset are less than or equal to that value.... Each dataset has three quartiles (first quartile is the sample 25th percentile, second quartile is the sample 50th percentile (median) and the third quartile is the sample 75th percentile* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Variance (ANOVA)\n",
    "\n",
    "**Analysis of Variance** can be defined as:\n",
    "<br>\n",
    "<br>\n",
    "*statistical formula used to compare variances across the means of different groups... where a range of scenarios use it to determine if there is any difference between the meands of different group* \n",
    "<br>\n",
    "\n",
    "https://www.tibco.com/reference-center/what-is-analysis-of-variance-anova. \n",
    "ANOVA due to its procedures helps select the best features when training a dataset, reduces complexity by limiting input variables and can determin if an independent variable is influencing a target variable. \n",
    "<br>\n",
    "<br>\n",
    "The outcome of the ANOVA is the 'F Statistic' which enables the researcher to conclude wheather or not the null hypothesis was supported or not. This is acheived through calculating the difference between the group variance and within group variances. ANOVA is important is ascertaining whether or not a mean values are statistically significant. ANOVA can also indirectly show if an independent variable is influencing the dependent variable.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Limitations of ANOVA**\n",
    "<br>\n",
    "- The test can only if there is significant difference between the means of at least two group but can't identify which pairs differ in its means. This requires ANOVA to be used in tandem with other statistical methods\n",
    "- Assumes uniform distribution limiting its ability to work with data that does not have a normal distribution and/or may contain outliers\n",
    "- Assumes Standard Deviation is similiar across the variable to avoid inaccurate conclusions being made\n",
    "<br>\n",
    "**Hypothesis Testing**\n",
    "<br>\n",
    "- **A Null Hypothesis(HO)** It is inferred there is no difference between the groups or means\n",
    "<br>\n",
    "- **An Alternative Hypothesis** It is inferred that there is a difference between groups and means\n",
    "<br>\n",
    "**Types of ANOVA**\n",
    "<br>\n",
    " - One Way ANOVA: The one-way ANOVA is suitable with only one independent variable with two or more levels.\n",
    " - Two Way ANOVA: When there are two or more independent variables that may have multple levels and includes every possible selection of variables and their levels.\n",
    " <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diet Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "import statsmodels.api as sn\n",
    "import numpy as np\n",
    "import collections as co\n",
    "import scipy.special as spec\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exploring the Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Diet Dataset contains information on 76 participants who undertook one of 3 diets (A, B, C). At the beginning and end of the trail, the participants weights were taken. The dataset contains information on their gender, allocated diet, height initial weight and their weight after six weeks. https://bioinformatics-core-shared-training.github.io/linear-models-r/anova.html https://bioinformatics-core-shared-training.github.io/linear-models-r/anova.html. This analysis will explore whether or not there is any correlation between the height of the participants and the weight lost, we can further explore which of the diest was most effective in assisting to lose weight and if the gender of the participants makes an impact on the outcome of the diet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing the Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dietdataset.csv') #first look at the dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dietdataset.csv', na_values=' ') # replacing empty cells with Nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'pre.weight': 'initialWeight'}, inplace=True) #changing the name of the pre.weight column\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Diet'] = df['Diet'].replace([1,2,3], ['Diet A', 'Diet B', 'Diet C']) #changing the names of the Diet variables \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weightloss'] = (df['initialWeight'] - df['weight6weeks']) #creating my dependent variable\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum() # looking into the Nan values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two instances where the gender is Nan. It appears that they participants did not fully participate in the trial. Due to the small number of datapoints, these data will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, how='all', subset=['gender'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Diet\")['weightloss'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Diet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# legend_elements() is a method so we must name our scatter plat scatter...\n",
    "scatter = plt.scatter(df.Height, df.initialWeight, c=df.gender, cmap=\"bwr\")\n",
    "\n",
    "# No arguments necessary, default is prop='colors'\n",
    "handles, labels = scatter.legend_elements()\n",
    "\n",
    "# Print out labels to see which appears first\n",
    "print(labels)\n",
    "\n",
    "# Re-name labels to Gender\n",
    "labels = ['Female','Male']\n",
    "leg = plt.legend(handles, labels, frameon=True)\n",
    "leg.get_frame().set_linewidth(1.0)\n",
    "leg.get_frame().set_edgecolor('b')\n",
    "plt.xlabel(\"X Axis\")\n",
    "plt.ylabel(\"Y Axis\")\n",
    "plt.title(\"Graph Name\")\n",
    "plt.show()\n",
    "# Reference\n",
    "# https://blog.finxter.com/matplotlib-scatter-plot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = plt.scatter(df.Height, df.initialWeight, c=df.gender,cmap=\"rainbow\", lw=0) #to assign male and female to the gender variables for 1 and 0\n",
    "plt.colorbar(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above chart, it is inferred from the two clusters that one group has higher instances of height and initial weight. It is well known that males are on avaerage taller and weigh more than their female counterparts. It is assumed that this group is male and the labels will be changed accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].replace([0,1], ['Female', 'Male']) #changing the names of the Diet variables \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count plot on single categorical variable\n",
    "sns.countplot(x ='Diet', hue ='gender', data = df)\n",
    " \n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Diet.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "The following are the hypothesis drawn from the initial exploratory data analysis:\n",
    "<br>\n",
    "\n",
    "#### Hypothesis 1\n",
    "\n",
    "<br>\n",
    "\n",
    "**A Null Hypothesis(HO)** The means of all diets are equal with respect to weightloss\n",
    "\n",
    "<br>\n",
    "\n",
    "**An Alternative Hypothesis** The mean of at least one diet is different with respect to weightloss\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Hypothesis 2\n",
    "\n",
    "<br>\n",
    "\n",
    "**A Null Hypothesis(HO)** The means of all genders are equal with respect to weightloss\n",
    "\n",
    "<br>\n",
    "\n",
    "**An Alternative Hypothesis** The mean of the genders are different with respect to weightloss\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions within the dataset\n",
    "***\n",
    "<br>\n",
    "Limitations of Assumptions\n",
    "https://www.statology.org/one-way-anova-r/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Assumption | Explaination |\n",
    "| :- | :- |\n",
    "**Your dependent variable should be measured at the interval or ratio level** | Dependent variables must be of 'metric measurements'https://www.statisticssolutions.com/free-resources/directory-of-statistical-analyses/assumptions-of-the-factorial-anova/is and the values take on any given number within a range https://www.javatpoint.com/anova-test-in-python https://www.statisticssolutions.com/free-resources/directory-of-statistical-analyses/assumptions-of-the-factorial-anova/ |\n",
    "|**Your independent variable should consist of two or more categorical independent groups** | The categorical groups shouldn't overlap, being part of one group shouldn't affect the chance of being part of another group.|\n",
    "|**You should have independence of observation** | There is no relationship between observations in each group or between the groups themselves. Each time there is a new datapoint in a group it is independent of all other datapoints in that group.|\n",
    "|**There should be no significant outliers** | It can be difficult to define outlier in the context of the data set.|\n",
    "|**Your dependent variable should be approximately normally distributed for each category of the independent**| When measured, the data points should take the form of a bell shaped curve.| https://www.statology.org/anova-assumptions/\n",
    "|**There needs to be a homogeneity of variances**| This assumption can be tested using a Levene's test for homogeneity of variances.|https://www.statology.org/anova-assumptions/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption 1: Dependent Variable\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen dependent variable in this instance is the metric weighloss which is measured in kgs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dependent variable\n",
    "dependent = df['weightloss']\n",
    "dependent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption 2: Independent Variable\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are going to look at two independent variables in this notebook, the author has chosen the following:\n",
    "<br>\n",
    "**Diet** - categories are: Diet A, Diet B and Diet C\n",
    "<br>\n",
    "**Gender** - catogories are: 0(which = Female) and 1 (which = Male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first independent variable\n",
    "independent = df['Diet']\n",
    "independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Assumption 3: Independence of Observation\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a study design issues rather than something that you can test for. For this to be reached the \"obersevations in each group are independent of each other and the observations within groups were obtained by a random sample\". https://www.statology.org/anova-assumptions/. There is no standardised test to ensure independence of observation, nonetheless if this assumption is violated, the results obtained from the same could be wrong. Strong, robust and ethical data collection is required. https://www.statisticshowto.com/assumption-of-independence/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Assumption 4: There should be no significant outliers\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers are unusual values in a dataset which can impact the analysis and distort the findings from research.https://statisticsbyjim.com/basics/remove-outliers/ The diet dataset has already been preprocessed to remove any null values. Some casues of outliers can include: data entry errors, sampling errors and natural variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://seaborn.pydata.org/generated/seaborn.boxplot.html\n",
    "sns.boxplot(x=dependent, y=independent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Assumption 5: Normal Distribution with the Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Distribution has two parameters: the mean of the distribution and the standard deviation. The data points are centred around the mean. The higher the standard deviation the flatter the curve will be. https://www.kaggle.com/gadaadhaarigeek/normal-distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To explore the normal distribution of each of the Diets in respect to the weightloss category\n",
    "#KDE of the three categories\n",
    "sns.displot(x=dependent, hue=independent, kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As inferred in the previous assumption, there are outliers in the dataset and they have an negative impact on the data analysis. Above, you can see that Diet A slightly positively skewed distribution where as the other two variables are minimally negatively skewed in their distribution. However, they all appear to have a bell shaped curve. https://www.analyticsvidhya.com/blog/2020/04/statistics-data-science-normal-distribution/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_points = ('DietA','weightloss')    \n",
    "  \n",
    "sm.qqplot = df(x = 'Diet A', y = 'weightloss', line = '45')\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset is small and there are potential outliers, a Shapiro Wilks test will be performed on each of the dependent variables (Diet A, Diet B and Diet C). \n",
    "Next, each of the dependent variables will be extracted and a Shapiro Wilks Normality Test to see if the the data accepts or rejects the hypothesis of normality. https://variation.com/wp-content/distribution_analyzer_help/hs141.htm#:~:text=Shapiro%2DWilks%20Normality%20Test&text=The%20Shapiro%2DWilks%20test%20for,than%20or%20equal%20to%200.05. Shapiro was selected because the size of the sample of the dataset is relatively small (*n = 76*). https://statistics.laerd.com/spss-tutorials/testing-for-normality-using-spss-statistics.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the Diet A weight losses\n",
    "weightloss_dietA = dependent[independent == 'Diet A']\n",
    "weightloss_dietA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.shapiro(weightloss_dietA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightloss_dietB = dependent[independent == 'Diet B']\n",
    "weightloss_dietB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.shapiro(weightloss_dietB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the Diet C weight losses\n",
    "weightloss_dietC = dependent[independent == 'Diet C']\n",
    "weightloss_dietC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss.shapiro(weightloss_dietC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each of the cases, the p > 0.05 which means that the test did not show evidence of non-normality. https://quantifyinghealth.com/report-shapiro-wilk-test/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise the normal distribution, the qq plot function is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pylab as py\n",
    " \n",
    "data_points = weightloss_dietB\n",
    "\n",
    "sm.qqplot(data_points, line ='45')\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pylab as py\n",
    "  \n",
    "np.random generates different random numbers\n",
    "whenever the code is executed\n",
    "Note: When you execute the same code \n",
    "the graph look different than shown below.\n",
    "  \n",
    "Random data points generated\n",
    "#data_points = np.random.normal(0, 1, 100)    \n",
    "data_points = weightloss_dietB\n",
    "\n",
    "sm.qqplot(data_points, line)\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Assumption 6: There needs to be a homogenity of variances\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assumption examines the distribution of spread of values around the means of continous variables. This aims to determine whether or not they are relatively similiar. https://methods.sagepub.com/reference/encyc-of-research-design/n179.xml. A p value of less than 0.05 idicates a violation of the assumption. \"Listwise deletion, logarithmic transformation or non parametric methods\" should be considered as a n alternative. https://www.scalestatistics.com/homogeneity-of-variance.html https://www.statisticssolutions.com/the-assumption-of-homogeneity-of-variance/ \n",
    "<br>\n",
    "Barlett's test for homogeneity is also conducted. This focus on determing a *\"test-statistic and finding the p value for the test-statistic, given the degrees of freedom and significance level\"*https://stattrek.com/anova/homogeneity/bartletts-test.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conducting levene's test of homogenity\n",
    "ss.levene(\n",
    "    dependent[independent == 'Diet A'],\n",
    "    dependent[independent == 'Diet B'],\n",
    "    dependent[independent == 'Diet C'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test shows a p value of higher than 0.05 indicating that there is no evidence of violation of this assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# conducting Bartlett's test\n",
    "from scipy.stats import bartlett # https://www.marsja.se/levenes-bartletts-test-of-equality-homogeneity-of-variance-in-python/\n",
    "\n",
    "# subsetting the data:\n",
    "DietA = df.query('Diet == \"Diet A\"')['weightloss']\n",
    "DietB = df.query('Diet == \"Diet B\"')['weightloss']\n",
    "DietC = df.query('Diet == \"Diet C\"')['weightloss']\n",
    "\n",
    "# Bartlett's test in Python with SciPy:\n",
    "stat, p = bartlett(DietA, DietB, DietC)\n",
    "\n",
    "# Get the results:\n",
    "print(stat, p)\n",
    "\n",
    "#to get each individual group\n",
    "df['Diet'].unique() #https://stattrek.com/anova/homogeneity/bartletts-test.aspx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p value is greater thans the significance level, indicating that the null hypothesis should not be rejected and the assumption is met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the Anova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fisher's One Way Anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA.\n",
    "ss.f_oneway(\n",
    "    dependent[independent == 'Diet A'],\n",
    "    dependent[independent == 'Diet B'],\n",
    "    dependent[independent == 'Diet C']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pvalue is under the recommended >0.05 indicating that there is a difference between the means of the groups. As the groups are not of same size, it is not possible to do individual t tests to explore the relationship between each of the Diet and the accompanying weight loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#create DataFrame\n",
    "df = pd.DataFrame({'score': [64, 66, 68, 75, 78, 94, 98, 79, 71, 80,\n",
    "                             91, 92, 93, 90, 97, 94, 82, 88, 95, 96,\n",
    "                             79, 78, 88, 94, 92, 85, 83, 85, 82, 81],\n",
    "                   'group': np.repeat(['a', 'b', 'c'], repeats=10)}) \n",
    "\n",
    "#perform Welch's ANOVA\n",
    "pg.welch_anova(dv='score', between='group', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "pg.pairwise_gameshowell(dv='weightloss', between='Diet', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#create DataFrame\n",
    "\n",
    "#perform Welch's ANOVA\n",
    "pg.welch_anova(dv='weightloss', between='Diet', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Hoc Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://statistics.laerd.com/statistical-guides/one-way-anova-statistical-guide-4.php\n",
    "# https://www.statology.org/tukey-test-python/\n",
    "# Import the Tukey HSD test from statsmodels\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "\n",
    "# endog is the dependent variable (weightloss).\n",
    "# groups is the independent variable (Diet).\n",
    "# alpha is the p-value threshold. In this case anything below 0.05 will reject the null hypothesis.\n",
    "tukey = pairwise_tukeyhsd(endog=df['weightloss'],\n",
    "                          groups=df['Diet'],\n",
    "                          alpha=0.05)\n",
    "\n",
    "# Print the Tukey table\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Diet C has demonstrated a greater weightloss after 6 weeks than that other two Diets the mean of the weightloss was greater than that of the other two. \n",
    "- Ensuring the dataset meets the assumptions can be difficult especially when the dataset may contain outliers. In this notebook, numerous test were used to ensure the assumptions were met due to the nature of the outliers. \n",
    "- Data collection is extremely important and should always be considered when first designing your hypothesis. In this dataset,  as the participants for each Diet were different counts, different tests has to be conducted. \n",
    "- For example, as it was a small dataset, a paired t test could have been utilised to determine the difference in means between the three Diets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
